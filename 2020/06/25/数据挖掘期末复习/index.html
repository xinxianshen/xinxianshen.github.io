<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">

<script>
    (function(){
        if(''){
            if (prompt('请输入密码') !== ''){
                alert('密码错误');
                history.back();
            }
        }
    })();
</script>








<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="数据挖掘,">










<meta name="description" content="概论什么是数据挖掘？数据挖掘的实际数据具有大量、不完全、有噪声、模糊的特点 数据挖掘技术统计学是关于认识客观现象总体数量特征和数量关系的科学。它是通过搜集、整理、分析统计资料，认识客观现象数量规律性的方法论科学。 eg：1、使用历史记录预测某公司未来的股票价格。是。我们可以通过建立模型预测未来的持续价值的股票价格。2、监视病人心率的异常变化。是。我们将构建一种类型为正常的心率和当异常心率的行为发生">
<meta name="keywords" content="数据挖掘">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘期末">
<meta property="og:url" content="www.xinxianshen.top/2020/06/25/数据挖掘期末复习/index.html">
<meta property="og:site_name" content="鑫先绅">
<meta property="og:description" content="概论什么是数据挖掘？数据挖掘的实际数据具有大量、不完全、有噪声、模糊的特点 数据挖掘技术统计学是关于认识客观现象总体数量特征和数量关系的科学。它是通过搜集、整理、分析统计资料，认识客观现象数量规律性的方法论科学。 eg：1、使用历史记录预测某公司未来的股票价格。是。我们可以通过建立模型预测未来的持续价值的股票价格。2、监视病人心率的异常变化。是。我们将构建一种类型为正常的心率和当异常心率的行为发生">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://s1.ax1x.com/2020/06/15/NCuUwq.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/06/20/NQ37X8.png">
<meta property="og:updated_time" content="2020-06-25T08:49:15.628Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘期末">
<meta name="twitter:description" content="概论什么是数据挖掘？数据挖掘的实际数据具有大量、不完全、有噪声、模糊的特点 数据挖掘技术统计学是关于认识客观现象总体数量特征和数量关系的科学。它是通过搜集、整理、分析统计资料，认识客观现象数量规律性的方法论科学。 eg：1、使用历史记录预测某公司未来的股票价格。是。我们可以通过建立模型预测未来的持续价值的股票价格。2、监视病人心率的异常变化。是。我们将构建一种类型为正常的心率和当异常心率的行为发生">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/06/15/NCuUwq.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="www.xinxianshen.top/2020/06/25/数据挖掘期末复习/">





  <title>数据挖掘期末 | 鑫先绅</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?10c111bee0b1ea1b7dfd2d7d277ac56a";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">鑫先绅</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">欢迎来到本站</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archive">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            archive
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.xinxianshen.top/2020/06/25/数据挖掘期末复习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xin">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="鑫先绅">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">数据挖掘期末</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-25T15:34:16+08:00">
                2020-06-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/期末复习/" itemprop="url" rel="index">
                    <span itemprop="name">期末复习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/06/25/数据挖掘期末复习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2020/06/25/数据挖掘期末复习/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2020/06/25/数据挖掘期末复习/" class="leancloud_visitors" data-flag-title="数据挖掘期末">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="概论"><a href="#概论" class="headerlink" title="概论"></a>概论</h1><h2 id="什么是数据挖掘？"><a href="#什么是数据挖掘？" class="headerlink" title="什么是数据挖掘？"></a>什么是数据挖掘？</h2><p>数据挖掘的实际数据具有大量、不完全、有噪声、模糊的特点</p>
<h2 id="数据挖掘技术"><a href="#数据挖掘技术" class="headerlink" title="数据挖掘技术"></a>数据挖掘技术</h2><p>统计学是关于认识客观现象总体数量特征和数量关系的科学。它是通过搜集、整理、分析统计资料，认识客观现象数量规律性的方法论科学。</p>
<p>eg：<br>1、使用历史记录预测某公司未来的股票价格。<br>是。我们可以通过建立模型预测未来的持续价值的股票价格。<br>2、监视病人心率的异常变化。<br>是。我们将构建一种类型为正常的心率和当异常心率的行为发生时报警。这将设计数据挖掘的领域被称为异常检测。这也可以看作是一种分类的问题，比如我们例子中正常和不正常两种心率的行为。<br>3、监视地震活动的地震波。<br>是。在这种情况下，我们将构建模型的不同类型的地震活动。这一例子说明，在区域的数据挖掘已知分级。</p>
<hr>
<h1 id="第二章-Pandas"><a href="#第二章-Pandas" class="headerlink" title="第二章 Pandas"></a>第二章 Pandas</h1><p>数据结构：Series（一维）、DataFrame（二维）、Panel（三维）</p>
<h3 id="数据结构Series的运算"><a href="#数据结构Series的运算" class="headerlink" title="数据结构Series的运算"></a>数据结构Series的运算</h3><p>mean()：平均值运算</p>
<pre><code>&gt;&gt;&gt; a = pd.Series([1,2,3,4])
&gt;&gt;&gt; print(a.mean())
输出：2.5

&gt;&gt;&gt; a = pd.Series([1,2,3,4])
&gt;&gt;&gt; b = pd.Series([1,2,1,2])
&gt;&gt;&gt; print(a+b)
输出：[2,4,4,6]
</code></pre><h4 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h4><p>loc用label来去定位， iloc用position来去定位</p>
<pre><code>&gt;&gt;&gt; df=pd.DataFrame({&#39;Name&#39;: [&#39;Joe&#39;, &#39;Mike&#39;, &#39;Jack&#39;, &#39;Rose&#39;, &#39;David&#39;], &#39;Age&#39;: [25, 32, 18, 15, 20]})
    Name  Age
0    Joe   25
1   Mike   32
2   Jack   18
3   Rose   15
4  David   20

&gt;&gt;&gt;df = df.set_index(&#39;Name&#39;) 
       Age
Name
Joe     25
Mike    32
Jack    18
Rose    15
David   20

&gt;&gt;&gt;df.loc[&#39;Joe&#39;]
Age    25
Name: Joe, dtype: int64
</code></pre><h4 id="groupby操作"><a href="#groupby操作" class="headerlink" title="groupby操作"></a>groupby操作</h4><pre><code>&gt;&gt;&gt;df = pd.DataFrame({&#39;key&#39;:[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;A&#39;,&#39;B&#39;,&#39;C&#39;], &#39;data&#39;:[0,5,10,5,10,15,10,15,20]})
  key  data
0   A     0
1   B     5
2   C    10
3   A     5
4   B    10
5   C    15
6   A    10
7   B    15
8   C    20

&gt;&gt;&gt;df.groupby(&#39;key&#39;).sum()
     data
key
A      15
B      30
C      45
</code></pre><h4 id="排序和排名"><a href="#排序和排名" class="headerlink" title="排序和排名"></a>排序和排名</h4><p>rank()，显示每个值排序的位置。</p>
<pre><code>&gt;&gt;&gt; df.rank()
   key  data
0  2.0   1.0
1  5.0   2.5
2  8.0   5.0
3  2.0   2.5
4  5.0   5.0
5  8.0   7.5
6  2.0   5.0
7  5.0   7.5
8  8.0   9.0
</code></pre><hr>
<h1 id="第三章-机器学习"><a href="#第三章-机器学习" class="headerlink" title="第三章 机器学习"></a>第三章 机器学习</h1><ul>
<li>监督学习：例如用户点击/购买预测、房价预测</li>
<li>无监督学习：例如邮件/新闻聚类</li>
<li>强化学习：例如动态系统以及机器人控制<br>数据集分为训练集和测试集<br><img src="https://s1.ax1x.com/2020/06/15/NCuUwq.png" alt="机器学习分类"></li>
</ul>
<p>人类学习的步骤：问题设定-&gt;数据准备-&gt;模型选择-&gt;学习-&gt;效果评测-&gt;记忆和运用<br>机器学习的步骤：问题设定-&gt;特征工程-&gt;模型选择-&gt;模型训练-&gt;模型评测-&gt;模型应用</p>
<p>sklearn模型的训练 <strong>fit()</strong><br>sklearn进行模型预测 <strong>predict()</strong></p>
<h3 id="机器学习评测的指标"><a href="#机器学习评测的指标" class="headerlink" title="机器学习评测的指标"></a>机器学习评测的指标</h3><p>训练误差：模型在训练集上的误差<br>泛化误差：模型在新样本上的误差</p>
<h4 id="分类常用的指标："><a href="#分类常用的指标：" class="headerlink" title="分类常用的指标："></a>分类常用的指标：</h4><p>准确率(accuracy)、AUC</p>
<h4 id="回归常用的指标："><a href="#回归常用的指标：" class="headerlink" title="回归常用的指标："></a>回归常用的指标：</h4><p>均方误差、方均根差RMSE</p>
<p>机器学习存在的问题“过拟合”</p>
<ul>
<li>过拟合：“你想得太多了”</li>
<li>欠拟合：“你太天真了”</li>
</ul>
<p>解决方法：<br>过拟合：</p>
<ul>
<li>找到更多的数据</li>
<li>增大正则化系数</li>
<li>减少特征(不推荐)</li>
<li>注意：降为解决不了过拟合</li>
</ul>
<p>欠拟合：</p>
<ul>
<li>找到更多的特征</li>
<li>减少正则化系数</li>
</ul>
<hr>
<h1 id="第四章-分类算法"><a href="#第四章-分类算法" class="headerlink" title="第四章 分类算法"></a>第四章 分类算法</h1><p><strong>贝叶斯公式</strong></p>
<script type="math/tex; mode=display">P(A|B)=\frac{P(AB)}{P(B)}=\frac{P(B|A)P(A)}{P(B)}</script><p>P(A|B)表示在B发生的条件下A发生的概率。</p>
<p><strong>贝叶斯算法的一些统计学概念</strong><br>频率&amp;概率<br>先验概率&amp;后验概率&amp;条件概率</p>
<p>例1：某地区居民肝癌的发病率为0.0004，现用甲胎蛋白法进行普查。医学研究表明，化验结果是有错检的可能性。已知患有肝癌的人其化验结果99%呈阳性（有病），而没患肝癌的人其化验结果99.9%呈阴性（无病）。<br>问：现某人的检查结果呈阳性，问他真正得肝癌的概率有多大？</p>
<p>答：设A=“结果检查呈阳性”，B=“被检查患者确实有肝癌”，已知P(B)=0.0004,P($\overline{B}$)=0.9996,P(A|B)=0.99,P(A|$\overline{B}$)=0.001<br> 由贝叶斯公式可得到：</p>
<script type="math/tex; mode=display">P(B|A)=\frac{P(AB)}{P(A)}=\frac{P(A|B)P(B)}{P(A|B)P(B)+P(A|\overline{B})P(\overline{B})}=\frac{0.99*0.0004}{0.99*0.0004+0.9996*0.001}=0.284</script><p>例2：如果某人首次化验，成果呈阳性。第二次复检，仍然呈阳性。请问该患者患肝癌的概率有多大？</p>
<p>答：首次检查呈阳性的患者，他的P(B)=0.284，复检仍然呈阳性，则患肝癌的概率为：</p>
<script type="math/tex; mode=display">P(B|A)=\frac{P(AB)}{P(A)}=\frac{P(A|B)P(B)}{P(A|B)P(B)+P(A|\overline{B})P(\overline{B})}=\frac{0.99*0.284}{0.99*0.284+0.716*0.001}\approx0.997</script><h3 id="距离"><a href="#距离" class="headerlink" title="距离"></a>距离</h3><p>很多基于向量空间的分类器在分类决策时用到距离的概念。</p>
<ol>
<li>欧式距离(Euclidean Distance)</li>
<li>曼哈顿距离(Manhattan Distance)</li>
<li>切比雪夫距离(Chebyshew Distance)</li>
</ol>
<p>例子：假如现在有三个人A、B和C(即样本A、样本B和样本C)，我们需要以性格、爱好这两个属性为依据来判断他们相互之间的相似度(距离)。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">样本</th>
<th style="text-align:center">性格</th>
<th style="text-align:center">爱好</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">A</td>
<td style="text-align:center">4</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">B</td>
<td style="text-align:center">9</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">C</td>
<td style="text-align:center">6</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://s1.ax1x.com/2020/06/20/NQ37X8.png" alt="A、B、C三个样本点的二维坐标投影图"><br>各种距离计算公式：<br>| 类别 | 计算公式(二维) | A、B样本 | A、C样本 |<br>| :—: | :—: | :—: | :—: |<br>|a     |b     |v     |   c  |</p>
<p>| 欧式距离 | $\sqrt{((x_1-x_2)^2+(y_1-y_2)^2))}$ | $\sqrt{5^2+1^2=26}$ | $\sqrt{2^2+3^2=13}$ |<br>| 曼哈顿距离 | $||x_1-x_2||+||y_1-y_2||$ | $||4-9||+||4-5||=6$ | $||4-6||+||4-1||=5$ |<br>| 切比雪夫距离 | $Max(|x_1-x_2|,|y_1-y_2|)$ | $Max(5,1)=5$    | $Max(2,3)=3$ |</p>
<h3 id="K近邻算法-KNN-优点："><a href="#K近邻算法-KNN-优点：" class="headerlink" title="K近邻算法(KNN)优点："></a>K近邻算法(KNN)优点：</h3><ol>
<li>容易理解，实现简单</li>
<li>只需保存训练样本和标记，无需估计参数和训练</li>
</ol>
<h3 id="K近邻算法-KNN-缺点："><a href="#K近邻算法-KNN-缺点：" class="headerlink" title="K近邻算法(KNN)缺点："></a>K近邻算法(KNN)缺点：</h3><ol>
<li>K值选择不固定，且对分类结果又较大影响</li>
<li>预测结果容易受噪声数据影响</li>
</ol>
<p>决策树算法：ID3、C4.5、CART<br>！！！<br>SVM不是决策树算法<br>K-Means不是分类算法<br>！！！</p>
<p>支持向量机(SVM)的三种情况分为</p>
<ul>
<li>线性可分</li>
<li>近线性可分</li>
<li>线性不可分<br>（ps.并不包括非线性可分）。</li>
</ul>
<hr>
<h1 id="第五章-回归算法"><a href="#第五章-回归算法" class="headerlink" title="第五章 回归算法"></a>第五章 回归算法</h1><p>回归算法包含如下三类：</p>
<ul>
<li>线性回归</li>
<li>多项式回归</li>
<li>逻辑回归</li>
</ul>
<p>一元线性回归举例：<br>汽车卖家做电视广告数量与卖出的汽车数量，如表所示，预测广告数量为6时，卖出的汽车数量？<br>|广告数|卖出汽车数|<br>|:—:|:—:|<br>|1|14|<br>|3|24|<br>|2|18|<br>|1|17|<br>|3|27|<br>|$\sum_{} x=10 \\ \overline{x}=2$|$\sum_{} y=100 \\ \overline{y}=20$|<br>使用最小二乘法计算：<br>分子=$(1-2)(14-20)+(3-2)(24-20)+(2-2)(18-20)+(1-2)(17-20)+(3-2)(27-20)=20$<br>分母=$(1-2)^2+(3-2)^2+(2-2)^2+(1-2)^2+(3-2)^2=4$<br>b1=20/4=5<br>b0=20-5<em>2=10<br>所以一元线性方程为：$y=b1</em>x+b0$，当广告数=6时，y=40</p>
<h3 id="常用的线性回归模型：Ridge回归和Lasso回归"><a href="#常用的线性回归模型：Ridge回归和Lasso回归" class="headerlink" title="常用的线性回归模型：Ridge回归和Lasso回归"></a>常用的线性回归模型：Ridge回归和Lasso回归</h3><p>Ridge回归与Lasso回归的出现是为了解决线性回归出现的过拟合现象。</p>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>逻辑回归算法是用来解决分类问题的<br>逻辑回归模型通过引入sigmoid函数将预测值限定为[0,1]间</p>
<hr>
<h1 id="第六章-聚类算法"><a href="#第六章-聚类算法" class="headerlink" title="第六章 聚类算法"></a>第六章 聚类算法</h1><p>主要聚类方式</p>
<ul>
<li>基于划分的方法</li>
<li>基于层次的方法</li>
<li>基于密度的方法</li>
</ul>
<p>代码例子</p>
<pre><code>import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
#读文件
data=pd.read_csv(&#39;C:/Users/gao20/Desktop/k_data.txt&#39;)
#画出原始数据
plt.scatter(data[&#39;Score_1&#39;],data[&#39;Score_2&#39;])
plt.show()
#使用聚类模型，分成两类
clu=KMeans(n_clusters=2)
#训练模型
clu.fit(data)
#获取训练后的标签并增加到原始数据
data[&#39;target&#39;]=clu.labels_
#分别获取标签分类的索引值
fail=data[&#39;target&#39;]==0
pas=data[&#39;target&#39;]==1
#画出分类数据
plt.scatter(data[fail][&#39;Score_1&#39;],data[fail][&#39;Score_2&#39;],marker=&#39;x&#39;)
plt.scatter(data[pas][&#39;Score_1&#39;],data[pas][&#39;Score_2&#39;],marker=&#39;+&#39;)
plt.show()
</code></pre><p>簇间相似度：单连接、全连接、组平均、质心距离</p>
<pre><code>import pandas as pd
import numpy as np
from sklearn.cluster import AgglomerativeClustering
import matplotlib.pyplot as plt

# 读取文件
data = pd.read_csv(r&#39;//k_data.txt&#39;)
# 使用层次聚类模型，族间距离采用单链接，分类族数量为3
clu = AgglomerativeClustering(linkage=&#39;ward&#39;, n_clusters=3)
# 训练模型
clu.fit (data)
# 获取训练后的标签并增加到原始数据
data[&#39;target&#39;] = clu.labels_
</code></pre><hr>
<h1 id="第七章-集成学习"><a href="#第七章-集成学习" class="headerlink" title="第七章 集成学习"></a>第七章 集成学习</h1><h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>定义：通过构建并结合多个机器学习器来完成学习任务，以达到获得比单个学习器更好的学习效果的一种机器学习方法。</p>
<p>集成学习中简单投票机制包括：一票否决、少数服从多数、有效多数</p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>机器学习中，随机森林是一个包含多个决策树的分类器</p>
<h3 id="Adaboost算法"><a href="#Adaboost算法" class="headerlink" title="Adaboost算法"></a>Adaboost算法</h3><p>Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器(强分类器)。<br>例子代码：</p>
<pre><code>#随机森林
from sklearn.ensemble import RandomForestClassifier,BaggingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
# 导入鸢尾花数据集
X,y=load_iris(return_X_y=True)
# 数据分割，测试数据占40%
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4)
# 调用随机森林模型，设置森林数目为10
clf = RandomForestClassifier(n_estimators=10)
# 训练模型
clf = clf.fit(X_train, y_train)
# 输出评分
clf.score(X_test,y_test)


#逻辑回归与Bagging算法
from sklearn.ensemble import BaggingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
# 导入鸢尾花数据集
X,y = load_iris(return_X_y=True)
# 数据分割，测试数据占20%
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)
# 调用逻辑回归模型，使用坐标轴下降法来迭代优化损失函数
lr = LogisticRegression(solver=&#39;liblinear&#39;,multi_class=&#39;auto&#39;)
# 调用Bagging算法模型，子分类器为逻辑回归分类模型，分类器数目为10
lr_bagging = BaggingClassifier(base_estimator=lr,n_estimators=10)
# 训练模型
lr_bagging = lr_bagging.fit(X_train, y_train)
# 输出评分
lr_bagging.score(X_test,y_test)
</code></pre><hr>
<h1 id="第八章-关联规则"><a href="#第八章-关联规则" class="headerlink" title="第八章 关联规则"></a>第八章 关联规则</h1><p>关联规则常见算法：Apriori、FP-Growth<br>协同过滤常见算法：基于用户、基于商品</p>
<h3 id="协同过滤算法-基于用户"><a href="#协同过滤算法-基于用户" class="headerlink" title="协同过滤算法(基于用户)"></a>协同过滤算法(基于用户)</h3><p>ABC三位观众对《老炮儿》和《唐人街探案》两部电影的调查数据，请用欧式距离计算观众A与B、观众A与C之间的兴趣相似度。其中欧式距离与相似度的映射关系为：相似度=1/(1+欧式距离)。<br>|用户|老炮儿|唐人街探案|<br>|:-:|:-:|:-:|<br>| A | 3.5 | 1.0 |<br>| B | 2.5 | 3.5 |<br>| C | 3.5 | 2.0 |</p>
<p>解：根据题干，可以得到ABC对应的坐标，<br>A(3.5,1.0)、B(2.5,3.5)、C(3.5,2.0)<br>计算A与B的距离：<script type="math/tex">Sab=\sqrt{((3.5-2.5)^2+(1.0-3.5)^2)}=2.69</script><br>计算A与C的距离：<script type="math/tex">Sac=\sqrt{((3.5-3.5)^2+(1.0-2.0)^2)}=1</script><br>A与B的相似度=1/(1+Sab)=0.27<br>A与c的相似度=1/(1+Sac)=0.5</p>
<h3 id="协同过滤算法-基于物品"><a href="#协同过滤算法-基于物品" class="headerlink" title="协同过滤算法(基于物品)"></a>协同过滤算法(基于物品)</h3><p>ABC三位观众对《寻龙诀》和《小门神》两部电影的调查数据，请用Pearson相关系数来计算《寻龙诀》和《小门神》的相似度。<br>|用户|寻龙诀|小门神|<br>|:-:|:-:|:-:|<br>| A | 3.5 | 3.0 |<br>| B | 5.0 | 3.5 |<br>| C | 3.0 | 2.0 |<br>Pearson相关系数公式为：<script type="math/tex">p_x,_y=\frac{\sum{XY}-\frac{\sum{X}\sum{Y}}{N}}{\sqrt{(\sum{X^2-\frac{(\sum{X})^2}{N}})(\sum{Y^2}-\frac{(\sum{Y})^2}{N})}}</script></p>
<p>《寻龙诀》(X)和《小门神》(Y)：<br>X=(3.5,5.0,3.0)<br>Y=(3.0,3.5,2.0)</p>
<ol>
<li>x和y的乘积再求和：3.5<em>3.0+5.0</em>3.5+3.0*2.0=34</li>
<li>x求和乘以y求和，再除以个数：((3.5+5.0+3.0)<em>(3.0</em>3.5*2.0))/3=32.58</li>
<li>x的平方和：3.5^2+5.0^2+3.0^2=46.25</li>
<li>x和的平方除以个数：((3.5+5.0+3.0)^2)/3=44.08</li>
<li>y的平方和：3.0^2+3.5^2+2.0^2=25.25</li>
<li>y和的平方除以个数：((3.+3.5+2.0)^2)/3=24.08<br>带入上式，p_xy=0.89</li>
</ol>
<hr>
<h1 id="第九章-图像数据分析"><a href="#第九章-图像数据分析" class="headerlink" title="第九章 图像数据分析"></a>第九章 图像数据分析</h1><h4 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h4><p>图像数据分析的内容包括内容分析、内容识别、内容检测等方面</p>
<h4 id="图像分类所在领域："><a href="#图像分类所在领域：" class="headerlink" title="图像分类所在领域："></a>图像分类所在领域：</h4><ul>
<li>计算机视觉</li>
<li>卫星领域</li>
<li>医学领域<br>语音识别不是图像分类的应用领域！！！</li>
</ul>
<h4 id="图像在计算机中的结构"><a href="#图像在计算机中的结构" class="headerlink" title="图像在计算机中的结构"></a>图像在计算机中的结构</h4><p>对于计算机来说，图像是一个由数字组成的三维数组<br>图像在计算机中由三个颜色通道组成，分别是红、绿、蓝，简称RGB</p>
<h4 id="图像分类的简单实现函数库"><a href="#图像分类的简单实现函数库" class="headerlink" title="图像分类的简单实现函数库"></a>图像分类的简单实现函数库</h4><p>OpenCV是一个用于图像处理、分析、机器视觉方面的开源函数库</p>
<h4 id="图像分类困难和挑战"><a href="#图像分类困难和挑战" class="headerlink" title="图像分类困难和挑战"></a>图像分类困难和挑战</h4><ul>
<li>视角变化</li>
<li>大小变化</li>
<li>形态变化</li>
<li>遮挡</li>
<li>光照条件</li>
<li>背景干扰</li>
</ul>
<h4 id="图像分类的特征提取"><a href="#图像分类的特征提取" class="headerlink" title="图像分类的特征提取"></a>图像分类的特征提取</h4><p>SIFT算法是一种图像特征提取的方法。<br>FAST特征点检测是公认的比较快速的特征点检测方法。</p>
<h4 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h4><p>人脸识别是基于人的脸部特征信息进行身份识别的一种生物识别技术。</p>
<hr>
<h1 id="第十章-文本数据分析"><a href="#第十章-文本数据分析" class="headerlink" title="第十章 文本数据分析"></a>第十章 文本数据分析</h1><p>什么是自然语言处理技术？</p>
<ul>
<li>自然语言处理就是用计算机来处理、理解以及运用人类语言；</li>
<li>自然语言处理技术目的就是将这些无意义数据变为计算机有意义并可以计算的数值型数据；</li>
<li>自然语言处理应用包括机器翻译、文档分类和文档聚类。</li>
</ul>
<h4 id="常用技术"><a href="#常用技术" class="headerlink" title="常用技术"></a>常用技术</h4><p>词干提取：将不同词性的单词还原成其原型。<br>词性标注：给定一个句子，确定每个单词的词性。<br>词干还原：自然语言到计算机数据转换常用的方法。</p>
<h4 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h4><p>NLTK模块是自然语言处理领域中，最常使用的模块，其处理的语言多为英文，NLTK中有一个已经准备好的中文分词资料库“jieba”。<br>自然语言处理应用领域中，Python程序的NLTK模块是最常用的模块，NLTK是构建python程序以处理人类语言数据的领先平台，并提供易于使用的接口。</p>
<p>自然语言到计算机数据转换被称为自然语言处理，常用的方法包括词频统计、TF-IDF等<br>TF-IDF是文本划分的一种常用技术，<br>情感分析是指通过对给定文本的词性分析从而判断该文本是消极的还是积极的过程。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/数据挖掘/" rel="tag"># 数据挖掘</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/06/25/考研书籍免费拿/" rel="next" title="考研书籍免费拿">
                <i class="fa fa-chevron-left"></i> 考研书籍免费拿
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="xin">
            
              <p class="site-author-name" itemprop="name">xin</p>
              <p class="site-description motion-element" itemprop="description">陪伴是最漫长的告白</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/2861186382/profile?rightmod=1&wvr=6&mod=personinfo" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-globe"></i>微博</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/xinxianshen?tab=repositories" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="1171204783@qq.com" target="_blank" title="邮箱">
                      
                        <i class="fa fa-fw fa-envelope"></i>邮箱</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#概论"><span class="nav-number">1.</span> <span class="nav-text">概论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是数据挖掘？"><span class="nav-number">1.1.</span> <span class="nav-text">什么是数据挖掘？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据挖掘技术"><span class="nav-number">1.2.</span> <span class="nav-text">数据挖掘技术</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第二章-Pandas"><span class="nav-number">2.</span> <span class="nav-text">第二章 Pandas</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据结构Series的运算"><span class="nav-number">2.0.1.</span> <span class="nav-text">数据结构Series的运算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#索引操作"><span class="nav-number">2.0.1.1.</span> <span class="nav-text">索引操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#groupby操作"><span class="nav-number">2.0.1.2.</span> <span class="nav-text">groupby操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#排序和排名"><span class="nav-number">2.0.1.3.</span> <span class="nav-text">排序和排名</span></a></li></ol></li></ol></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#第三章-机器学习"><span class="nav-number">3.</span> <span class="nav-text">第三章 机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#机器学习评测的指标"><span class="nav-number">3.0.1.</span> <span class="nav-text">机器学习评测的指标</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#分类常用的指标："><span class="nav-number">3.0.1.1.</span> <span class="nav-text">分类常用的指标：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#回归常用的指标："><span class="nav-number">3.0.1.2.</span> <span class="nav-text">回归常用的指标：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第四章-分类算法"><span class="nav-number">4.</span> <span class="nav-text">第四章 分类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#距离"><span class="nav-number">4.0.1.</span> <span class="nav-text">距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K近邻算法-KNN-优点："><span class="nav-number">4.0.2.</span> <span class="nav-text">K近邻算法(KNN)优点：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K近邻算法-KNN-缺点："><span class="nav-number">4.0.3.</span> <span class="nav-text">K近邻算法(KNN)缺点：</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第五章-回归算法"><span class="nav-number">5.</span> <span class="nav-text">第五章 回归算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#常用的线性回归模型：Ridge回归和Lasso回归"><span class="nav-number">5.0.1.</span> <span class="nav-text">常用的线性回归模型：Ridge回归和Lasso回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归"><span class="nav-number">5.0.2.</span> <span class="nav-text">逻辑回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第六章-聚类算法"><span class="nav-number">6.</span> <span class="nav-text">第六章 聚类算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第七章-集成学习"><span class="nav-number">7.</span> <span class="nav-text">第七章 集成学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#集成学习"><span class="nav-number">7.0.1.</span> <span class="nav-text">集成学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机森林"><span class="nav-number">7.0.2.</span> <span class="nav-text">随机森林</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adaboost算法"><span class="nav-number">7.0.3.</span> <span class="nav-text">Adaboost算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第八章-关联规则"><span class="nav-number">8.</span> <span class="nav-text">第八章 关联规则</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协同过滤算法-基于用户"><span class="nav-number">8.0.1.</span> <span class="nav-text">协同过滤算法(基于用户)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#协同过滤算法-基于物品"><span class="nav-number">8.0.2.</span> <span class="nav-text">协同过滤算法(基于物品)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第九章-图像数据分析"><span class="nav-number">9.</span> <span class="nav-text">第九章 图像数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#图像分类"><span class="nav-number">9.0.0.1.</span> <span class="nav-text">图像分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#图像分类所在领域："><span class="nav-number">9.0.0.2.</span> <span class="nav-text">图像分类所在领域：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#图像在计算机中的结构"><span class="nav-number">9.0.0.3.</span> <span class="nav-text">图像在计算机中的结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#图像分类的简单实现函数库"><span class="nav-number">9.0.0.4.</span> <span class="nav-text">图像分类的简单实现函数库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#图像分类困难和挑战"><span class="nav-number">9.0.0.5.</span> <span class="nav-text">图像分类困难和挑战</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#图像分类的特征提取"><span class="nav-number">9.0.0.6.</span> <span class="nav-text">图像分类的特征提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#人脸识别"><span class="nav-number">9.0.0.7.</span> <span class="nav-text">人脸识别</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#第十章-文本数据分析"><span class="nav-number">10.</span> <span class="nav-text">第十章 文本数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#常用技术"><span class="nav-number">10.0.0.1.</span> <span class="nav-text">常用技术</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NLTK"><span class="nav-number">10.0.0.2.</span> <span class="nav-text">NLTK</span></a></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xin</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("SUxt9sC5apdwtioYeUf2WLtf-gzGzoHsz", "DQb1iwyKQ3NlL7m1kI5cSnkq");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
